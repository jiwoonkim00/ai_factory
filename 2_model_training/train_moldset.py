#!/usr/bin/env python3
"""
Moldset ë°ì´í„°ì…‹ í•™ìŠµ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (ë¦¬ëˆ…ìŠ¤/A100 ìµœì í™”)

ì‚¬ìš©ë²•:
    python train_moldset.py
    python train_moldset.py --config all
    python train_moldset.py --config normal_only
"""

import os
import sys
import argparse
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
project_root = Path(__file__).resolve().parent.parent
dataset_path = project_root / "dataset"
training_script = Path(__file__).resolve().parent / "train_anomaly_detector.py"

def check_gpu():
    """GPU í™•ì¸"""
    try:
        import torch
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
            print(f"âœ… GPU ê°ì§€: {gpu_name}")
            print(f"   GPU ë©”ëª¨ë¦¬: {gpu_memory:.1f} GB")
            return True
        else:
            print("âš ï¸  GPU ì—†ìŒ - CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤")
            return False
    except ImportError:
        print("âš ï¸  PyTorch ë¯¸ì„¤ì¹˜")
        return False

def check_dataset():
    """ë°ì´í„°ì…‹ íŒŒì¼ í™•ì¸"""
    datasets = {
        'labeled': dataset_path / "moldset_labeled.csv",
        'labeled_rg3': dataset_path / "moldset_labeled_rg3.csv",
        'labeled_cn7': dataset_path / "moldset_labeled_cn7.csv",
        'unlabeled_rg3': dataset_path / "moldset_unlabeled_rg3.csv",
        'unlabeled_cn7': dataset_path / "moldset_unlabeled_cn7.csv",
        'unlabeled': dataset_path / "unlabeled_data.csv",
        'labeled_data': dataset_path / "labeled_data.csv"
    }
    
    available = {}
    for name, path in datasets.items():
        if path.exists():
            size_mb = path.stat().st_size / (1024 * 1024)
            available[name] = {'path': path, 'size_mb': size_mb}
            print(f"   âœ… {name}: {path.name} ({size_mb:.2f} MB)")
        else:
            print(f"   âŒ {name}: íŒŒì¼ ì—†ìŒ")
    
    return available

def train_labeled_normal_only():
    """ì •ìƒ ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ"""
    print("\n" + "="*80)
    print("1ï¸âƒ£  ì •ìƒ ë°ì´í„°ë§Œ ì‚¬ìš© (Unsupervised í•™ìŠµ)")
    print("="*80)
    
    dataset_file = dataset_path / "moldset_labeled.csv"
    if not dataset_file.exists():
        print(f"âŒ ë°ì´í„°ì…‹ íŒŒì¼ ì—†ìŒ: {dataset_file}")
        return False
    
    cmd = [
        sys.executable,
        str(training_script),
        "--data_path", str(dataset_file),
        "--seq_len", "50",
        "--epochs", "20",
        "--use_label",
        "--use_normal_only",
        "--model_type", "TimesNet"
    ]
    
    print(f"ì‹¤í–‰ ëª…ë ¹ì–´: {' '.join(cmd)}")
    os.system(' '.join(cmd))
    return True

def train_labeled_all():
    """Label ì •ë³´ ì‚¬ìš© (ì •ìƒ/ì´ìƒ ëª¨ë‘ í¬í•¨)"""
    print("\n" + "="*80)
    print("2ï¸âƒ£  Label ì •ë³´ ì‚¬ìš© (ì •ìƒ/ì´ìƒ ëª¨ë‘ í¬í•¨)")
    print("="*80)
    
    dataset_file = dataset_path / "moldset_labeled.csv"
    if not dataset_file.exists():
        print(f"âŒ ë°ì´í„°ì…‹ íŒŒì¼ ì—†ìŒ: {dataset_file}")
        return False
    
    cmd = [
        sys.executable,
        str(training_script),
        "--data_path", str(dataset_file),
        "--seq_len", "50",
        "--epochs", "20",
        "--use_label",
        "--model_type", "TimesNet"
    ]
    
    print(f"ì‹¤í–‰ ëª…ë ¹ì–´: {' '.join(cmd)}")
    os.system(' '.join(cmd))
    return True

def train_unlabeled():
    """Unlabeled ë°ì´í„°ë¡œ í•™ìŠµ"""
    print("\n" + "="*80)
    print("3ï¸âƒ£  Unlabeled ë°ì´í„° ì‚¬ìš©")
    print("="*80)
    
    # ì‘ì€ íŒŒì¼ë¶€í„° ì‹œë„
    dataset_files = [
        dataset_path / "moldset_unlabeled_rg3.csv",
        dataset_path / "moldset_unlabeled_cn7.csv",
        dataset_path / "unlabeled_data.csv"
    ]
    
    dataset_file = None
    for f in dataset_files:
        if f.exists():
            dataset_file = f
            break
    
    if dataset_file is None:
        print("âŒ Unlabeled ë°ì´í„°ì…‹ íŒŒì¼ ì—†ìŒ")
        return False
    
    cmd = [
        sys.executable,
        str(training_script),
        "--data_path", str(dataset_file),
        "--seq_len", "50",
        "--epochs", "20",
        "--model_type", "TimesNet"
    ]
    
    print(f"ì‹¤í–‰ ëª…ë ¹ì–´: {' '.join(cmd)}")
    os.system(' '.join(cmd))
    return True

def train_custom(data_path, seq_len=50, epochs=20, use_label=False, use_normal_only=False, batch_size=None):
    """ì»¤ìŠ¤í…€ í•™ìŠµ"""
    cmd = [
        sys.executable,
        str(training_script),
        "--data_path", str(data_path),
        "--seq_len", str(seq_len),
        "--epochs", str(epochs),
        "--model_type", "TimesNet"
    ]
    
    if use_label:
        cmd.append("--use_label")
    if use_normal_only:
        cmd.append("--use_normal_only")
    if batch_size:
        cmd.extend(["--batch_size", str(batch_size)])
    
    print(f"ì‹¤í–‰ ëª…ë ¹ì–´: {' '.join(cmd)}")
    os.system(' '.join(cmd))

def main():
    parser = argparse.ArgumentParser(description="Moldset ë°ì´í„°ì…‹ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument(
        "--config",
        type=str,
        default="normal_only",
        choices=["normal_only", "all", "unlabeled", "all_configs"],
        help="í•™ìŠµ ì„¤ì • (normal_only: ì •ìƒ ë°ì´í„°ë§Œ, all: Label ëª¨ë‘, unlabeled: Unlabeled, all_configs: ëª¨ë“  ì„¤ì •)"
    )
    parser.add_argument(
        "--data_path",
        type=str,
        default=None,
        help="ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ê²½ë¡œ"
    )
    parser.add_argument(
        "--seq_len",
        type=int,
        default=50,
        help="ì‹œí€€ìŠ¤ ê¸¸ì´"
    )
    parser.add_argument(
        "--epochs",
        type=int,
        default=20,
        help="í•™ìŠµ ì—í¬í¬"
    )
    parser.add_argument(
        "--use_label",
        action="store_true",
        help="Label ì •ë³´ ì‚¬ìš©"
    )
    parser.add_argument(
        "--use_normal_only",
        action="store_true",
        help="ì •ìƒ ë°ì´í„°ë§Œ ì‚¬ìš©"
    )
    parser.add_argument(
        "--batch_size",
        type=int,
        default=None,
        help="ë°°ì¹˜ í¬ê¸° (Noneì´ë©´ ìë™ ìµœì í™”)"
    )
    
    args = parser.parse_args()
    
    print("="*80)
    print("ğŸš€ Moldset ë°ì´í„°ì…‹ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ (ë¦¬ëˆ…ìŠ¤/A100 ìµœì í™”)")
    print("="*80)
    
    # GPU í™•ì¸
    print("\nğŸ” GPU í™•ì¸:")
    has_gpu = check_gpu()
    
    # ë°ì´í„°ì…‹ í™•ì¸
    print("\nğŸ“‚ ë°ì´í„°ì…‹ í™•ì¸:")
    available_datasets = check_dataset()
    
    if not available_datasets:
        print("\nâŒ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    if has_gpu:
        os.environ['CUDA_VISIBLE_DEVICES'] = '0'
        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'
        print("\nâš™ï¸  í™˜ê²½ ë³€ìˆ˜ ì„¤ì •:")
        print(f"   CUDA_VISIBLE_DEVICES=0")
        print(f"   PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512")
    
    # ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ì‚¬ìš©
    if args.data_path:
        print(f"\nğŸ“Š ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ì‚¬ìš©: {args.data_path}")
        train_custom(
            data_path=args.data_path,
            seq_len=args.seq_len,
            epochs=args.epochs,
            use_label=args.use_label,
            use_normal_only=args.use_normal_only,
            batch_size=args.batch_size
        )
        return
    
    # ì„¤ì •ì— ë”°ë¥¸ í•™ìŠµ ì‹¤í–‰
    if args.config == "normal_only":
        train_labeled_normal_only()
    elif args.config == "all":
        train_labeled_all()
    elif args.config == "unlabeled":
        train_unlabeled()
    elif args.config == "all_configs":
        print("\nğŸ”„ ëª¨ë“  ì„¤ì •ìœ¼ë¡œ í•™ìŠµ ì‹œì‘...\n")
        train_labeled_normal_only()
        train_labeled_all()
        train_unlabeled()
    
    print("\n" + "="*80)
    print("âœ… í•™ìŠµ ì™„ë£Œ!")
    print("="*80)
    print("\ní•™ìŠµëœ ëª¨ë¸ ìœ„ì¹˜:")
    model_path = project_root / "2_model_training" / "anomaly_model_timesnet.pkl"
    if model_path.exists():
        size_mb = model_path.stat().st_size / (1024 * 1024)
        print(f"  âœ… {model_path} ({size_mb:.2f} MB)")
    else:
        print(f"  âš ï¸  {model_path} (ì•„ì§ ìƒì„±ë˜ì§€ ì•ŠìŒ)")

if __name__ == "__main__":
    main()

