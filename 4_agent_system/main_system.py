"""
4_agent_system/main_system.py
AI ììœ¨ ìš´ì˜ ê³µì • ì‹œìŠ¤í…œ - ë©”ì¸ ì‹¤í–‰ íŒŒì¼

ìˆ˜ì • ì‚¬í•­: Import ê²½ë¡œ ìˆ˜ì •
"""

import os
import sys
from datetime import datetime
from typing import Dict
import json

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

# Agent imports
from agents.detection_agent import DetectionAgent
from agents.retrieval_agent import RetrievalAgent
from agents.action_agent import ActionAgent
from agents.pm_agent import PMRecommendationAgent
from agents.report_agent import ReportAgent

# Model imports
from models.lora_inference import LoRAInferenceEngine

# LangGraph
try:
    from langgraph.graph import StateGraph, END
except ImportError:
    print("âš ï¸  LangGraph ë¯¸ì„¤ì¹˜. ì„¤ì¹˜: pip install langgraph")
    StateGraph = None
    END = None

# Utils
from utils.state import AgentState


class ManufacturingAISystem:
    """ì „ì²´ Multi-Agent ì‹œìŠ¤í…œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°"""
    
    def __init__(self,
                 detection_model_type: str = "TimesNet",  # "TimesNet", "rule_based"
                 lora_model_path: str = None,
                 knowledge_base_path: str = None):
        """
        Args:
            detection_model_type: 'TimesNet', 'AnomalyTransformer', 'TranAD', 'rule_based'
            lora_model_path: LoRA ëª¨ë¸ ê²½ë¡œ
            knowledge_base_path: RAG ì§€ì‹ ë² ì´ìŠ¤ ê²½ë¡œ
        """
        
        print("=" * 80)
        print("ğŸ­ AI ììœ¨ ìš´ì˜ ê³µì • ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        print("=" * 80)
        
        # ê¸°ë³¸ ê²½ë¡œ ì„¤ì • (config ì‚¬ìš©)
        try:
            from utils.config import LORA_MODEL_PATH, KNOWLEDGE_BASE_PATH
            if lora_model_path is None:
                lora_model_path = str(LORA_MODEL_PATH)
            if knowledge_base_path is None:
                knowledge_base_path = str(KNOWLEDGE_BASE_PATH)
        except ImportError:
            # config ì—†ì„ ë•Œ í´ë°±
            project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            if lora_model_path is None:
                lora_model_path = os.path.join(project_root, "2_model_training", "manufacturing_lora_output")
            if knowledge_base_path is None:
                knowledge_base_path = os.path.join(project_root, "3_knowledge_base", "knowledge_base")
        
        # LoRA ì—”ì§„ ì´ˆê¸°í™”
        try:
            self.lora_engine = LoRAInferenceEngine(
                lora_adapter_path=lora_model_path
            )
            if not self.lora_engine.is_loaded:
                print("âš ï¸  LoRA ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨. Base ëª¨ë¸ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                self.lora_engine = None
        except Exception as e:
            print(f"âš ï¸  LoRA ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("   Base ëª¨ë¸ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            import traceback
            traceback.print_exc()
            self.lora_engine = None
        
        # Agents ì´ˆê¸°í™”
        try:
            self.detection_agent = DetectionAgent(
                model_type=detection_model_type,
                seq_len=50
            )
        except Exception as e:
            print(f"âš ï¸  Detection Agent ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
        
        try:
            self.retrieval_agent = RetrievalAgent(knowledge_base_path)
        except Exception as e:
            print(f"âš ï¸  Retrieval Agent ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
        
        try:
            self.action_agent = ActionAgent(self.lora_engine)
        except Exception as e:
            print(f"âš ï¸  Action Agent ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
        
        try:
            self.pm_agent = PMRecommendationAgent()
        except Exception as e:
            print(f"âš ï¸  PM Agent ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
        
        try:
            self.report_agent = ReportAgent(self.lora_engine)
        except Exception as e:
            print(f"âš ï¸  Report Agent ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
        
        # LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±
        if StateGraph is not None:
            self.workflow = self._build_workflow()
        else:
            self.workflow = None
            print("âš ï¸  LangGraph ì—†ìŒ. ìˆœì°¨ ì‹¤í–‰ ëª¨ë“œ")
        
        print("\nâœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
        print("=" * 80)
    
    def _build_workflow(self) -> StateGraph:
        """LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±"""
        
        workflow = StateGraph(AgentState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("detect", self.detection_agent.run)
        workflow.add_node("retrieve", self.retrieval_agent.run)
        workflow.add_node("action", self.action_agent.run)
        workflow.add_node("pm", self.pm_agent.run)
        workflow.add_node("report", self.report_agent.run)
        
        # ì—£ì§€ ì •ì˜ (ìˆœì°¨ ì‹¤í–‰)
        workflow.set_entry_point("detect")
        workflow.add_edge("detect", "retrieve")
        workflow.add_edge("retrieve", "action")
        workflow.add_edge("action", "pm")
        workflow.add_edge("pm", "report")
        workflow.add_edge("report", END)
        
        return workflow.compile()
    
    def process_anomaly_event(self,
                              equipment_id: str,
                              sensor_data: Dict[str, float]) -> Dict:
        """
        ì´ìƒ ì´ë²¤íŠ¸ ì²˜ë¦¬ (ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰)
        
        Args:
            equipment_id: ì„¤ë¹„ ID
            sensor_data: ì„¼ì„œ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        
        print(f"\n{'='*80}")
        print(f"ğŸš€ ì´ìƒ ì´ë²¤íŠ¸ ì²˜ë¦¬ ì‹œì‘")
        print(f"{'='*80}")
        print(f"ì„¤ë¹„: {equipment_id}")
        print(f"ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ì„¼ì„œ: {sensor_data}")
        
        # ì´ˆê¸° ìƒíƒœ êµ¬ì„±
        initial_state = {
            "equipment_id": equipment_id,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "sensor_data": sensor_data,
            "messages": [],
            "workflow_start_time": datetime.now().isoformat(),
            "workflow_status": "running"
        }
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        start_time = datetime.now()
        
        try:
            if self.workflow is not None:
                # LangGraph ì‚¬ìš©
                result = self.workflow.invoke(initial_state)
            else:
                # ìˆœì°¨ ì‹¤í–‰
                result = self._sequential_execution(initial_state)
            
            # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
            elapsed = (datetime.now() - start_time).total_seconds()
            result['workflow_status'] = 'completed'
            result['elapsed_time'] = elapsed
            
            print(f"\n{'='*80}")
            print(f"âœ… ì›Œí¬í”Œë¡œìš° ì™„ë£Œ (ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ)")
            print(f"{'='*80}")
            
            # ê²°ê³¼ ìš”ì•½
            self._print_summary(result)
            
            return result
            
        except Exception as e:
            print(f"\nâŒ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def _sequential_execution(self, state: Dict) -> Dict:
        """ìˆœì°¨ ì‹¤í–‰ (LangGraph ì—†ì„ ë•Œ)"""
        
        state = self.detection_agent.run(state)
        state = self.retrieval_agent.run(state)
        state = self.action_agent.run(state)
        state = self.pm_agent.run(state)
        state = self.report_agent.run(state)
        
        return state
    
    def _print_summary(self, result: Dict):
        """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\nğŸ“Š ì‹¤í–‰ ê²°ê³¼ ìš”ì•½:")
        print(f"   - ì´ìƒ ì—¬ë¶€: {'ğŸš¨ ì´ìƒ ê°ì§€' if result.get('is_anomaly') else 'âœ… ì •ìƒ'}")
        
        if result.get('is_anomaly'):
            print(f"   - ì´ìƒ ìœ í˜•: {result.get('anomaly_type')}")
            print(f"   - ì‹ ë¢°ë„: {result.get('anomaly_score', 0):.1%}")
            print(f"   - ê²€ìƒ‰ëœ ì‚¬ë¡€: {len(result.get('similar_cases', []))}ê°œ")
            print(f"   - ì›ì¸ í›„ë³´: {len(result.get('root_causes', []))}ê°œ")
            print(f"   - ì²´í¬ë¦¬ìŠ¤íŠ¸: {len(result.get('checklist', []))}ê°œ")
            print(f"   - Health Score: {result.get('health_score', 0):.1%}")
            print(f"   - ê³ ì¥ ìœ„í—˜ë„: {result.get('failure_risk', 0):.1%}")
            print(f"   - PM ì¶”ì²œ: {len(result.get('pm_recommendations', []))}ê°œ")
        
        print(f"\nğŸ”„ ì‹¤í–‰ ë¡œê·¸:")
        for msg in result.get('messages', []):
            print(f"   {msg}")


# ============================================================================
# ë©”ì¸ ì‹¤í–‰ ì˜ˆì œ
# ============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)
    system = ManufacturingAISystem(
        detection_model_type="rule_based"  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©
    )
    
    # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ 1: ì˜¨ë„ ì´ìƒ
    print("\n" + "=" * 80)
    print("í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ 1: ì˜¨ë„ ì´ìƒ")
    print("=" * 80)
    
    result1 = system.process_anomaly_event(
        equipment_id="ì‚¬ì¶œê¸°-2í˜¸ê¸°",
        sensor_data={
            "temperature": 235.5,
            "pressure": 120.0,
            "vibration": 1.2,
            "cycle_time": 52
        }
    )
    
    # ê²°ê³¼ ì €ì¥
    output_dir = os.path.join(os.path.dirname(os.path.dirname(current_dir)), "outputs", "results")
    os.makedirs(output_dir, exist_ok=True)
    
    output_file = os.path.join(output_dir, "result_temperature_anomaly.json")
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(result1, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"\nâœ… ê²°ê³¼ ì €ì¥: {output_file}")
    
    # 8D Report ì¶œë ¥
    print("\n" + "=" * 80)
    print("ğŸ“„ ìƒì„±ëœ 8D Report")
    print("=" * 80)
    print(result1.get('report_8d', 'N/A')[:500] + "...")
    
    
    # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ 2: ì •ìƒ ìš´ì „
    print("\n\n" + "=" * 80)
    print("í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ 2: ì •ìƒ ìš´ì „")
    print("=" * 80)
    
    result2 = system.process_anomaly_event(
        equipment_id="CNC-1í˜¸ê¸°",
        sensor_data={
            "temperature": 200.0,
            "pressure": 120.0,
            "vibration": 1.0,
            "cycle_time": 50
        }
    )
    
    print("\nâœ… ì •ìƒ ìš´ì „ í™•ì¸")


if __name__ == "__main__":
    # í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    
    os.makedirs(os.path.join(project_root, "3_knowledge_base", "knowledge_base"), exist_ok=True)
    os.makedirs(os.path.join(project_root, "2_model_training", "manufacturing_lora_output"), exist_ok=True)
    os.makedirs(os.path.join(project_root, "outputs", "results"), exist_ok=True)
    
    print("""
    âš ï¸  ì£¼ì˜ì‚¬í•­:
    1. Detection Agent: ê·œì¹™ ê¸°ë°˜ ë˜ëŠ” DeepOD í•™ìŠµ í•„ìš”
       â†’ cd 2_model_training && python test.py --model TimesNet
    
    2. LoRA ëª¨ë¸: train_lora.py ì‹¤í–‰ í•„ìš”
       â†’ cd 2_model_training && python train_lora.py
    
    3. í•„ìš” íŒ¨í‚¤ì§€:
       â†’ pip install langchain langgraph faiss-cpu sentence-transformers deepod
    """)
    
    # ì‹¤í–‰
    main()