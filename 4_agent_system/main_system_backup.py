"""
AI ììœ¨ ìš´ì˜ ê³µì • ì‹œìŠ¤í…œ - ì „ì²´ Multi-Agent êµ¬ì¡°
ìŠ¤ë§ˆíŠ¸ ì œì¡° AI Agent í•´ì»¤í†¤ 2025

ì „ì²´ íë¦„:
Detection â†’ Retrieval (RAG) â†’ Action (LoRA) â†’ PM â†’ Report (LoRA) â†’ Dashboard
"""

import os
import json
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
from enum import Enum

# LangGraph
from langgraph.graph import StateGraph, END
from typing_extensions import TypedDict
import operator
from typing import Annotated

# AI/ML
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel

# RAG
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document


# ============================================================================
# 1. ìƒíƒœ ì •ì˜ (State Definition)
# ============================================================================

class AgentState(TypedDict):
    """Multi-Agent ì‹œìŠ¤í…œ ì „ì²´ ìƒíƒœ"""
    # ì…ë ¥
    equipment_id: str
    timestamp: str
    sensor_data: Dict[str, Any]
    
    # Detection Agent ì¶œë ¥
    is_anomaly: bool
    anomaly_type: str
    anomaly_score: float
    
    # Retrieval Agent ì¶œë ¥
    rag_context: str
    similar_cases: List[Dict]
    
    # Action Agent ì¶œë ¥ (LoRA)
    root_causes: List[Dict]
    action_guide: str
    checklist: List[str]
    
    # PM Agent ì¶œë ¥
    health_score: float
    failure_risk: float
    pm_recommendations: List[Dict]
    
    # Report Agent ì¶œë ¥ (LoRA)
    report_8d: str
    
    # ë©”ì‹œì§€ ë¡œê·¸
    messages: Annotated[List[str], operator.add]
    
    # ë©”íƒ€ë°ì´í„°
    workflow_start_time: str
    workflow_status: str


# ============================================================================
# 2. Detection Agent (ì´ìƒ íƒì§€)
# ============================================================================

class AnomalyDetectionModel:
    """ì‹œê³„ì—´ ì´ìƒ íƒì§€ ëª¨ë¸ (LSTM/AutoEncoder)"""
    
    def __init__(self, model_path: Optional[str] = None):
        self.model = None
        self.threshold = 0.7
        
        if model_path and os.path.exists(model_path):
            self.load_model(model_path)
        else:
            print("âš ï¸  ì´ìƒ íƒì§€ ëª¨ë¸ ë¯¸ì„¤ì¹˜. ê·œì¹™ ê¸°ë°˜ íƒì§€ ì‚¬ìš©")
    
    def load_model(self, model_path: str):
        """í•™ìŠµëœ ì´ìƒ íƒì§€ ëª¨ë¸ ë¡œë“œ"""
        # TODO: ì‹¤ì œ LSTM/AutoEncoder ëª¨ë¸ ë¡œë“œ
        pass
    
    def detect_anomaly(self, sensor_data: Dict[str, float]) -> tuple[bool, float, str]:
        """
        ì´ìƒ íƒì§€ ìˆ˜í–‰
        
        Returns:
            (is_anomaly, anomaly_score, anomaly_type)
        """
        # ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ íƒì§€ (MVPìš©)
        anomaly_type = "ì •ìƒ"
        anomaly_score = 0.0
        
        # ì˜¨ë„ ì²´í¬
        if 'temperature' in sensor_data:
            temp = sensor_data['temperature']
            if temp > 230 or temp < 170:
                anomaly_score = max(anomaly_score, 0.9)
                anomaly_type = "ì˜¨ë„ ì´ìƒ"
        
        # ì••ë ¥ ì²´í¬
        if 'pressure' in sensor_data:
            pressure = sensor_data['pressure']
            if pressure < 80 or pressure > 160:
                anomaly_score = max(anomaly_score, 0.85)
                anomaly_type = "ì••ë ¥ ì´ìƒ"
        
        # ì§„ë™ ì²´í¬
        if 'vibration' in sensor_data:
            vibration = sensor_data['vibration']
            if vibration > 2.5:
                anomaly_score = max(anomaly_score, 0.8)
                anomaly_type = "ì§„ë™ ì´ìƒ"
        
        # ì‚¬ì´í´íƒ€ì„ ì²´í¬
        if 'cycle_time' in sensor_data:
            cycle_time = sensor_data['cycle_time']
            if cycle_time > 75:
                anomaly_score = max(anomaly_score, 0.75)
                anomaly_type = "ì‚¬ì´í´íƒ€ì„ ì§€ì—°"
        
        is_anomaly = anomaly_score >= self.threshold
        
        return is_anomaly, anomaly_score, anomaly_type


class DetectionAgent:
    """Detection Agent - ê³µì • ì´ìƒ íƒì§€"""
    
    def __init__(self, model_path: Optional[str] = None):
        self.detector = AnomalyDetectionModel(model_path)
        print("âœ… Detection Agent ì´ˆê¸°í™” ì™„ë£Œ")
    
    def run(self, state: AgentState) -> AgentState:
        """ì´ìƒ íƒì§€ ì‹¤í–‰"""
        print(f"\n{'='*60}")
        print("ğŸ” Detection Agent ì‹¤í–‰ ì¤‘...")
        print(f"{'='*60}")
        
        # ì´ìƒ íƒì§€
        is_anomaly, score, anomaly_type = self.detector.detect_anomaly(
            state['sensor_data']
        )
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state['is_anomaly'] = is_anomaly
        state['anomaly_score'] = score
        state['anomaly_type'] = anomaly_type
        state['messages'].append(
            f"Detection: {'ì´ìƒ ê°ì§€' if is_anomaly else 'ì •ìƒ'} "
            f"(Score: {score:.2f}, Type: {anomaly_type})"
        )
        
        print(f"ê²°ê³¼: {'ğŸš¨ ì´ìƒ ê°ì§€' if is_anomaly else 'âœ… ì •ìƒ'}")
        print(f"ì´ìƒ ìœ í˜•: {anomaly_type}")
        print(f"ì‹ ë¢°ë„: {score:.1%}")
        
        return state


# ============================================================================
# 3. Retrieval Agent (RAG ê¸°ë°˜ ê·¼ê±° ê²€ìƒ‰)
# ============================================================================

class RAGSystem:
    """RAG ì‹œìŠ¤í…œ - ê³¼ê±° ì´ë ¥, ë§¤ë‰´ì–¼ ê²€ìƒ‰"""
    
    def __init__(self, knowledge_base_path: str = "./knowledge_base"):
        self.knowledge_base_path = knowledge_base_path
        self.embeddings = None
        self.vectorstore = None
        self.documents = []
        
        print("ğŸ“š RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        self._initialize_embeddings()
        self._load_knowledge_base()
    
    def _initialize_embeddings(self):
        """ì„ë² ë”© ëª¨ë¸ ë¡œë“œ"""
        try:
            self.embeddings = HuggingFaceEmbeddings(
                model_name="BAAI/bge-m3",
                model_kwargs={'device': 'cuda' if torch.cuda.is_available() else 'cpu'}
            )
            print("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (bge-m3)")
        except Exception as e:
            print(f"âš ï¸  ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            # Fallback
            self.embeddings = HuggingFaceEmbeddings(
                model_name="sentence-transformers/all-MiniLM-L6-v2"
            )
    
    def _load_knowledge_base(self):
        """ì§€ì‹ ë² ì´ìŠ¤ ë¡œë“œ ë° ë²¡í„°í™”"""
        os.makedirs(self.knowledge_base_path, exist_ok=True)
        
        # ìƒ˜í”Œ ë¬¸ì„œ ìƒì„± (ì‹¤ì œë¡œëŠ” íŒŒì¼ì—ì„œ ë¡œë“œ)
        sample_docs = self._create_sample_documents()
        
        # ë¬¸ì„œ ë¶„í• 
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50
        )
        
        self.documents = []
        for doc_dict in sample_docs:
            doc = Document(
                page_content=doc_dict['content'],
                metadata=doc_dict['metadata']
            )
            self.documents.append(doc)
        
        splits = text_splitter.split_documents(self.documents)
        
        # Vector DB ìƒì„±
        if len(splits) > 0:
            self.vectorstore = FAISS.from_documents(splits, self.embeddings)
            print(f"âœ… ì§€ì‹ ë² ì´ìŠ¤ ë¡œë“œ ì™„ë£Œ ({len(splits)}ê°œ ì²­í¬)")
        else:
            print("âš ï¸  ì§€ì‹ ë² ì´ìŠ¤ ë¬¸ì„œ ì—†ìŒ")
    
    def _create_sample_documents(self) -> List[Dict]:
        """ìƒ˜í”Œ ì§€ì‹ ë² ì´ìŠ¤ ë¬¸ì„œ ìƒì„±"""
        return [
            {
                'content': """
                [ê³¼ê±° ì´ë ¥ #2023-08-15]
                ì„¤ë¹„: ì‚¬ì¶œê¸°-2í˜¸ê¸°
                ì¦ìƒ: ì‹¤ë¦°ë” ì˜¨ë„ ê¸‰ìƒìŠ¹ (235Â°C)
                ì›ì¸: íˆí„° ì½”ì¼ ë‹¨ì„ 
                ì¡°ì¹˜: íˆí„° êµì²´ í›„ ì •ìƒí™”
                ì†Œìš”ì‹œê°„: 4ì‹œê°„
                """,
                'metadata': {
                    'type': 'ê³¼ê±°_ì´ë ¥',
                    'equipment': 'ì‚¬ì¶œê¸°',
                    'anomaly': 'ì˜¨ë„_ì´ìƒ'
                }
            },
            {
                'content': """
                [ì„¤ë¹„ ë§¤ë‰´ì–¼ 3.2ì ˆ - ì˜¨ë„ ê´€ë¦¬]
                ì‹¤ë¦°ë” ì˜¨ë„ê°€ ì„¤ì •ê°’ Â±15Â°Cë¥¼ ë²—ì–´ë‚  ê²½ìš°:
                1. íˆí„° ì €í•­ê°’ ì¸¡ì • (ì •ìƒ: 30~35Î©)
                2. ì—´ì „ëŒ€ ì„¼ì„œ ì ê²€
                3. ì˜¨ë„ ì œì–´ê¸° íŒŒë¼ë¯¸í„° í™•ì¸
                ê¸´ê¸‰ ì¡°ì¹˜: ì¦‰ì‹œ ì„¤ë¹„ ì •ì§€
                """,
                'metadata': {
                    'type': 'ë§¤ë‰´ì–¼',
                    'equipment': 'ì‚¬ì¶œê¸°',
                    'section': 'ì˜¨ë„_ê´€ë¦¬'
                }
            },
            {
                'content': """
                [Trouble Shooting Guide]
                ì••ë ¥ ì´ìƒ ë°œìƒ ì‹œ ì ê²€ ìˆœì„œ:
                1. ìœ ì••íŒí”„ ì••ë ¥ ê²Œì´ì§€ í™•ì¸
                2. ì‹¤ë¦°ë” ì”° ëˆ„ìœ  ì ê²€
                3. ë°°ê´€ ì—°ê²°ë¶€ ì ê²€
                4. ì••ë ¥ ì„¼ì„œ êµì •
                ì£¼ì˜: ì••ë ¥ì´ ì •ìƒ ë²”ìœ„ì˜ 70% ì´í•˜ë©´ ì¦‰ì‹œ ì •ì§€
                """,
                'metadata': {
                    'type': 'Trouble_Shooting',
                    'equipment': 'ì „ì²´',
                    'anomaly': 'ì••ë ¥_ì´ìƒ'
                }
            },
            {
                'content': """
                [ì •ë¹„ ì´ë ¥ DB]
                ìµœê·¼ 6ê°œì›” ì§„ë™ ì´ìƒ ì¼€ì´ìŠ¤:
                - ë² ì–´ë§ ë§ˆëª¨: 5ê±´ (í‰ê·  ë³µêµ¬ ì‹œê°„ 6ì‹œê°„)
                - êµ¬ë™ë¶€ ì–¸ë°¸ëŸ°ìŠ¤: 3ê±´ (í‰ê·  ë³µêµ¬ ì‹œê°„ 4ì‹œê°„)
                - ì²´ê²°ë¶€ í’€ë¦¼: 2ê±´ (í‰ê·  ë³µêµ¬ ì‹œê°„ 2ì‹œê°„)
                ì˜ˆë°© ì¡°ì¹˜: ì›” 1íšŒ ì§„ë™ ì¸¡ì • ë° ë² ì–´ë§ ê·¸ë¦¬ìŠ¤ ì£¼ì…
                """,
                'metadata': {
                    'type': 'ì •ë¹„_ì´ë ¥',
                    'anomaly': 'ì§„ë™_ì´ìƒ',
                    'period': 'ìµœê·¼_6ê°œì›”'
                }
            },
            {
                'content': """
                [8D Report ì˜ˆì‹œ #2024-03-20]
                D1: íŒ€ êµ¬ì„± - ìƒì‚°ê¸°ìˆ íŒ€, í’ˆì§ˆíŒ€
                D2: ë¬¸ì œ ì •ì˜ - ì‚¬ì¶œê¸° 3í˜¸ê¸° ì˜¨ë„ ì´ìƒ
                D3: ì„ì‹œ ì¡°ì¹˜ - ì„¤ë¹„ ì •ì§€, ìƒì‚°í’ˆ ê²©ë¦¬
                D4: ê·¼ë³¸ ì›ì¸ - ëƒ‰ê°ìˆ˜ ìˆœí™˜ íŒí”„ ê³ ì¥
                D5: ì˜êµ¬ ëŒ€ì±… - íŒí”„ êµì²´, ì˜ˆë¹„í’ˆ í™•ë³´
                D6: ì‹¤í–‰ ë° ê²€ì¦ - 48ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì •ìƒ
                D7: ì¬ë°œ ë°©ì§€ - PM ì£¼ê¸° ì¡°ì •, ì„¼ì„œ ì¶”ê°€
                """,
                'metadata': {
                    'type': '8D_Report',
                    'equipment': 'ì‚¬ì¶œê¸°',
                    'date': '2024-03-20'
                }
            }
        ]
    
    def search(self, query: str, k: int = 3) -> List[Dict]:
        """ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰"""
        if self.vectorstore is None:
            return []
        
        results = self.vectorstore.similarity_search_with_score(query, k=k)
        
        retrieved = []
        for doc, score in results:
            retrieved.append({
                'content': doc.page_content,
                'metadata': doc.metadata,
                'similarity': float(1 - score)  # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜
            })
        
        return retrieved


class RetrievalAgent:
    """Retrieval Agent - RAG ê¸°ë°˜ ê·¼ê±° ê²€ìƒ‰"""
    
    def __init__(self, knowledge_base_path: str = "./knowledge_base"):
        self.rag = RAGSystem(knowledge_base_path)
        print("âœ… Retrieval Agent ì´ˆê¸°í™” ì™„ë£Œ")
    
    def run(self, state: AgentState) -> AgentState:
        """RAG ê²€ìƒ‰ ì‹¤í–‰"""
        print(f"\n{'='*60}")
        print("ğŸ“– Retrieval Agent ì‹¤í–‰ ì¤‘...")
        print(f"{'='*60}")
        
        # ì´ìƒì´ ì•„ë‹ˆë©´ ìŠ¤í‚µ
        if not state['is_anomaly']:
            state['messages'].append("Retrieval: ì´ìƒ ì—†ìŒ, ê²€ìƒ‰ ìŠ¤í‚µ")
            return state
        
        # ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
        query = f"""
        ì„¤ë¹„: {state['equipment_id']}
        ì´ìƒ ìœ í˜•: {state['anomaly_type']}
        ì„¼ì„œ ë°ì´í„°: {state['sensor_data']}
        """
        
        # RAG ê²€ìƒ‰
        similar_cases = self.rag.search(query, k=3)
        
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        rag_context = "\n\n".join([
            f"[ê²€ìƒ‰ ê²°ê³¼ #{i+1}] (ìœ ì‚¬ë„: {case['similarity']:.1%})\n{case['content']}"
            for i, case in enumerate(similar_cases)
        ])
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state['similar_cases'] = similar_cases
        state['rag_context'] = rag_context
        state['messages'].append(f"Retrieval: {len(similar_cases)}ê°œ ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰ ì™„ë£Œ")
        
        print(f"ê²€ìƒ‰ ì™„ë£Œ: {len(similar_cases)}ê°œ ë¬¸ì„œ")
        for i, case in enumerate(similar_cases):
            print(f"  [{i+1}] {case['metadata'].get('type', 'Unknown')} "
                  f"(ìœ ì‚¬ë„: {case['similarity']:.1%})")
        
        return state


# ============================================================================
# 4. Action Agent (LoRA ëª¨ë¸ ê¸°ë°˜ ì¡°ì¹˜ ìƒì„±)
# ============================================================================

class LoRAInferenceEngine:
    """LoRA íŒŒì¸íŠœë‹ ëª¨ë¸ ì¶”ë¡  ì—”ì§„"""
    
    def __init__(self, 
                 base_model_path: str = "Qwen/Qwen2.5-7B-Instruct",
                 lora_adapter_path: str = "./manufacturing_lora_output"):
        
        self.base_model_path = base_model_path
        self.lora_adapter_path = lora_adapter_path
        self.model = None
        self.tokenizer = None
        
        print(f"ğŸ¤– LoRA ëª¨ë¸ ë¡œë”© ì¤‘...")
        self._load_model()
    
    def _load_model(self):
        """Base ëª¨ë¸ + LoRA ì–´ëŒ‘í„° ë¡œë“œ"""
        try:
            # í† í¬ë‚˜ì´ì €
            self.tokenizer = AutoTokenizer.from_pretrained(
                self.base_model_path,
                trust_remote_code=True
            )
            
            # Base ëª¨ë¸
            self.model = AutoModelForCausalLM.from_pretrained(
                self.base_model_path,
                torch_dtype=torch.bfloat16,
                device_map="auto",
                trust_remote_code=True
            )
            
            # LoRA ì–´ëŒ‘í„° (í•™ìŠµ ì™„ë£Œ í›„)
            if os.path.exists(self.lora_adapter_path):
                self.model = PeftModel.from_pretrained(
                    self.model, 
                    self.lora_adapter_path
                )
                print(f"âœ… LoRA ì–´ëŒ‘í„° ë¡œë“œ ì™„ë£Œ: {self.lora_adapter_path}")
            else:
                print(f"âš ï¸  LoRA ì–´ëŒ‘í„° ì—†ìŒ. Base ëª¨ë¸ë§Œ ì‚¬ìš©: {self.base_model_path}")
            
            self.model.eval()
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def generate(self, 
                 instruction: str,
                 input_text: str,
                 max_new_tokens: int = 1024,
                 temperature: float = 0.7) -> str:
        """í…ìŠ¤íŠ¸ ìƒì„±"""
        
        messages = [
            {"role": "system", "content": instruction},
            {"role": "user", "content": input_text}
        ]
        
        text = self.tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )
        
        inputs = self.tokenizer(text, return_tensors="pt").to(self.model.device)
        
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=max_new_tokens,
                temperature=temperature,
                top_p=0.9,
                do_sample=True,
                repetition_penalty=1.1
            )
        
        response = self.tokenizer.decode(
            outputs[0][inputs['input_ids'].shape[1]:],
            skip_special_tokens=True
        )
        
        return response


class ActionAgent:
    """Action Agent - ì›ì¸ ë¶„ì„ ë° ì¡°ì¹˜ ê°€ì´ë“œ ìƒì„± (LoRA)"""
    
    def __init__(self, lora_engine: LoRAInferenceEngine):
        self.lora_engine = lora_engine
        print("âœ… Action Agent ì´ˆê¸°í™” ì™„ë£Œ")
    
    def run(self, state: AgentState) -> AgentState:
        """ì¡°ì¹˜ ê°€ì´ë“œ ìƒì„±"""
        print(f"\n{'='*60}")
        print("ğŸ”§ Action Agent ì‹¤í–‰ ì¤‘... (LoRA ëª¨ë¸)")
        print(f"{'='*60}")
        
        # ì´ìƒì´ ì•„ë‹ˆë©´ ìŠ¤í‚µ
        if not state['is_anomaly']:
            state['messages'].append("Action: ì´ìƒ ì—†ìŒ, ì¡°ì¹˜ ìŠ¤í‚µ")
            return state
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        instruction = "ë‹¹ì‹ ì€ ì œì¡° í˜„ì¥ì˜ ì „ë¬¸ ì„¤ë¹„ ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤. ê³µì • ì´ìƒ ìƒí™©ì— ëŒ€í•´ ì›ì¸ì„ ë¶„ì„í•˜ê³ , êµ¬ì²´ì ì¸ ì¡°ì¹˜ ê°€ì´ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."
        
        input_text = f"""[ê³µì • ì´ìƒ ì´ë²¤íŠ¸]
ì„¤ë¹„: {state['equipment_id']}
ë°œìƒì‹œê°: {state['timestamp']}
ì´ìƒìœ í˜•: {state['anomaly_type']}

[ì„¼ì„œ ë°ì´í„°]
{self._format_sensor_data(state['sensor_data'])}

[RAG ê²€ìƒ‰ ê²°ê³¼]
{state.get('rag_context', 'ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ')}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì›ì¸ ë¶„ì„ê³¼ ì¡°ì¹˜ ê°€ì´ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”."""
        
        # LoRA ëª¨ë¸ë¡œ ìƒì„±
        print("LoRA ëª¨ë¸ ì¶”ë¡  ì¤‘...")
        action_guide = self.lora_engine.generate(instruction, input_text)
        
        # ì›ì¸ í›„ë³´ íŒŒì‹± (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        root_causes = self._parse_root_causes(action_guide)
        checklist = self._parse_checklist(action_guide)
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state['root_causes'] = root_causes
        state['action_guide'] = action_guide
        state['checklist'] = checklist
        state['messages'].append("Action: ì¡°ì¹˜ ê°€ì´ë“œ ìƒì„± ì™„ë£Œ (LoRA)")
        
        print(f"âœ… ì¡°ì¹˜ ê°€ì´ë“œ ìƒì„± ì™„ë£Œ ({len(action_guide)} ì)")
        print(f"   - ì›ì¸ í›„ë³´: {len(root_causes)}ê°œ")
        print(f"   - ì²´í¬ë¦¬ìŠ¤íŠ¸: {len(checklist)}ê°œ")
        
        return state
    
    def _format_sensor_data(self, sensor_data: Dict) -> str:
        """ì„¼ì„œ ë°ì´í„° í¬ë§·íŒ…"""
        lines = []
        for key, value in sensor_data.items():
            lines.append(f"- {key}: {value}")
        return "\n".join(lines)
    
    def _parse_root_causes(self, text: str) -> List[Dict]:
        """ì›ì¸ í›„ë³´ íŒŒì‹±"""
        causes = []
        lines = text.split('\n')
        
        for line in lines:
            if '1ìˆœìœ„:' in line or '**1ìˆœìœ„:' in line:
                cause = line.split(':')[1].strip().replace('**', '')
                causes.append({'rank': 1, 'cause': cause, 'probability': 'ë†’ìŒ'})
            elif '2ìˆœìœ„:' in line or '**2ìˆœìœ„:' in line:
                cause = line.split(':')[1].strip().replace('**', '')
                causes.append({'rank': 2, 'cause': cause, 'probability': 'ì¤‘ê°„'})
            elif '3ìˆœìœ„:' in line or '**3ìˆœìœ„:' in line:
                cause = line.split(':')[1].strip().replace('**', '')
                causes.append({'rank': 3, 'cause': cause, 'probability': 'ë‚®ìŒ'})
        
        return causes if causes else [{'rank': 1, 'cause': 'ì›ì¸ ë¶„ì„ ì¤‘', 'probability': 'ë¯¸ì •'}]
    
    def _parse_checklist(self, text: str) -> List[str]:
        """ì²´í¬ë¦¬ìŠ¤íŠ¸ íŒŒì‹±"""
        checklist = []
        lines = text.split('\n')
        
        for line in lines:
            if line.strip().startswith('â–¡'):
                item = line.strip()[2:].strip()
                checklist.append(item)
        
        return checklist if checklist else ['ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„± ì¤‘']


# ============================================================================
# 5. PM Recommendation Agent (ì˜ˆë°©ë³´ì „ ì¶”ì²œ)
# ============================================================================

class PMRecommendationAgent:
    """PM Agent - ì˜ˆë°©ë³´ì „ ì¶”ì²œ"""
    
    def __init__(self):
        print("âœ… PM Agent ì´ˆê¸°í™” ì™„ë£Œ")
    
    def run(self, state: AgentState) -> AgentState:
        """ì˜ˆë°©ë³´ì „ ì¶”ì²œ"""
        print(f"\n{'='*60}")
        print("ğŸ”§ PM Agent ì‹¤í–‰ ì¤‘...")
        print(f"{'='*60}")
        
        # Health Score ê³„ì‚° (ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜)
        health_score, failure_risk = self._calculate_health_score(
            state['sensor_data'],
            state.get('is_anomaly', False)
        )
        
        # PM ì¶”ì²œ
        pm_recommendations = self._generate_pm_recommendations(
            state['equipment_id'],
            health_score,
            failure_risk,
            state.get('anomaly_type', 'ì •ìƒ')
        )
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state['health_score'] = health_score
        state['failure_risk'] = failure_risk
        state['pm_recommendations'] = pm_recommendations
        state['messages'].append(
            f"PM: Health Score {health_score:.1%}, "
            f"ê³ ì¥ ìœ„í—˜ë„ {failure_risk:.1%}"
        )
        
        print(f"âœ… PM ë¶„ì„ ì™„ë£Œ")
        print(f"   - Health Score: {health_score:.1%}")
        print(f"   - ê³ ì¥ ìœ„í—˜ë„: {failure_risk:.1%}")
        print(f"   - ì¶”ì²œ í•­ëª©: {len(pm_recommendations)}ê°œ")
        
        return state
    
    def _calculate_health_score(self, sensor_data: Dict, is_anomaly: bool) -> tuple[float, float]:
        """ì„¤ë¹„ ê±´ê°•ë„ ë° ê³ ì¥ ìœ„í—˜ë„ ê³„ì‚°"""
        
        # ê¸°ë³¸ ì ìˆ˜
        health_score = 0.85
        failure_risk = 0.15
        
        # ì´ìƒ ë°œìƒ ì‹œ ê°ì 
        if is_anomaly:
            health_score -= 0.30
            failure_risk += 0.40
        
        # ì„¼ì„œ ê°’ ê¸°ë°˜ ì¡°ì •
        if 'temperature' in sensor_data:
            temp = sensor_data['temperature']
            if temp > 220 or temp < 180:
                health_score -= 0.10
                failure_risk += 0.15
        
        if 'vibration' in sensor_data:
            vib = sensor_data['vibration']
            if vib > 2.0:
                health_score -= 0.15
                failure_risk += 0.20
        
        # ë²”ìœ„ ì œí•œ
        health_score = max(0.0, min(1.0, health_score))
        failure_risk = max(0.0, min(1.0, failure_risk))
        
        return health_score, failure_risk
    
    def _generate_pm_recommendations(self, 
                                     equipment_id: str,
                                     health_score: float,
                                     failure_risk: float,
                                     anomaly_type: str) -> List[Dict]:
        """PM ì¶”ì²œ í•­ëª© ìƒì„±"""
        recommendations = []
        
        # ê³ ìœ„í—˜
        if failure_risk > 0.5:
            recommendations.append({
                'priority': 'HIGH',
                'action': '48ì‹œê°„ ë‚´ ê¸´ê¸‰ ì ê²€ í•„ìš”',
                'items': ['ì£¼ìš” ë¶€í’ˆ êµì²´ ê²€í† ', 'ì „ë¬¸ê°€ ì§„ë‹¨ ìš”ì²­'],
                'estimated_time': '4~8ì‹œê°„'
            })
        
        # ì¤‘ìœ„í—˜
        elif failure_risk > 0.3:
            recommendations.append({
                'priority': 'MEDIUM',
                'action': '1ì£¼ì¼ ë‚´ ì •ê¸° ì ê²€ ê¶Œì¥',
                'items': ['ì„¼ì„œ êµì •', 'ì†Œëª¨í’ˆ êµì²´'],
                'estimated_time': '2~4ì‹œê°„'
            })
        
        # ì €ìœ„í—˜
        else:
            recommendations.append({
                'priority': 'LOW',
                'action': 'ì •ê¸° PM ìŠ¤ì¼€ì¤„ ìœ ì§€',
                'items': ['ìœ¡ì•ˆ ì ê²€', 'ì²­ì†Œ ë° ê¸‰ìœ '],
                'estimated_time': '1~2ì‹œê°„'
            })
        
        # ì´ìƒ ìœ í˜•ë³„ ì¶”ê°€ ê¶Œì¥ì‚¬í•­
        if 'ì˜¨ë„' in anomaly_type:
            recommendations.append({
                'priority': 'HIGH',
                'action': 'ì˜¨ë„ ê´€ë ¨ ë¶€í’ˆ ì§‘ì¤‘ ì ê²€',
                'items': ['íˆí„° ì €í•­ê°’ ì¸¡ì •', 'ëƒ‰ê° ì‹œìŠ¤í…œ ì ê²€', 'ë‹¨ì—´ì¬ êµì²´'],
                'estimated_time': '3~5ì‹œê°„'
            })
        
        elif 'ì••ë ¥' in anomaly_type:
            recommendations.append({
                'priority': 'HIGH',
                'action': 'ìœ ì•• ì‹œìŠ¤í…œ ì ê²€',
                'items': ['íŒí”„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸', 'ì”° êµì²´', 'ë°°ê´€ ì²­ì†Œ'],
                'estimated_time': '4~6ì‹œê°„'
            })
        
        elif 'ì§„ë™' in anomaly_type:
            recommendations.append({
                'priority': 'HIGH',
                'action': 'êµ¬ë™ë¶€ ì •ë°€ ì ê²€',
                'items': ['ë² ì–´ë§ êµì²´', 'ì •ë ¬ ì¡°ì •', 'ì²´ê²° í† í¬ í™•ì¸'],
                'estimated_time': '5~8ì‹œê°„'
            })
        
        return recommendations


# ============================================================================
# 6. Report Agent (8D ë³´ê³ ì„œ ìë™ ìƒì„± - LoRA)
# ============================================================================

class ReportAgent:
    """Report Agent - 8D ë³´ê³ ì„œ ìë™ ìƒì„± (LoRA)"""
    
    def __init__(self, lora_engine: LoRAInferenceEngine):
        self.lora_engine = lora_engine
        print("âœ… Report Agent ì´ˆê¸°í™” ì™„ë£Œ")
    
    def run(self, state: AgentState) -> AgentState:
        """8D ë³´ê³ ì„œ ìƒì„±"""
        print(f"\n{'='*60}")
        print("ğŸ“„ Report Agent ì‹¤í–‰ ì¤‘... (LoRA ëª¨ë¸)")
        print(f"{'='*60}")
        
        # ì´ìƒì´ ì•„ë‹ˆë©´ ê°„ë‹¨í•œ ë³´ê³ ì„œ
        if not state['is_anomaly']:
            state['report_8d'] = self._generate_normal_report(state)
            state['messages'].append("Report: ì •ìƒ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
            return state
        
        # 8D ë³´ê³ ì„œ ìƒì„± í”„ë¡¬í”„íŠ¸
        instruction = "ë‹¹ì‹ ì€ ì œì¡° í˜„ì¥ì˜ í’ˆì§ˆ ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 8D Reportë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."
        
        input_text = f"""[ì´ìƒ ìƒí™© ìš”ì•½]
ì„¤ë¹„: {state['equipment_id']}
ë°œìƒì‹œê°: {state['timestamp']}
ì´ìƒìœ í˜•: {state['anomaly_type']}

[ì›ì¸ ë¶„ì„ ê²°ê³¼]
{self._format_root_causes(state.get('root_causes', []))}

[ì¡°ì¹˜ ê°€ì´ë“œ]
{state.get('action_guide', 'ì¡°ì¹˜ ê°€ì´ë“œ ì—†ìŒ')[:500]}...

[PM ì¶”ì²œì‚¬í•­]
- Health Score: {state.get('health_score', 0):.1%}
- ê³ ì¥ ìœ„í—˜ë„: {state.get('failure_risk', 0):.1%}
{self._format_pm_recommendations(state.get('pm_recommendations', []))}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ 8D Report (D1~D7)ë¥¼ ì‘ì„±í•˜ì„¸ìš”."""
        
        # LoRA ëª¨ë¸ë¡œ ìƒì„±
        print("8D Report ìƒì„± ì¤‘...")
        report_8d = self.lora_engine.generate(
            instruction, 
            input_text,
            max_new_tokens=1024
        )
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state['report_8d'] = report_8d
        state['messages'].append("Report: 8D Report ìƒì„± ì™„ë£Œ (LoRA)")
        
        print(f"âœ… 8D Report ìƒì„± ì™„ë£Œ ({len(report_8d)} ì)")
        
        return state
    
    def _generate_normal_report(self, state: AgentState) -> str:
        """ì •ìƒ ìš´ì „ ë³´ê³ ì„œ"""
        return f"""[ì •ìƒ ìš´ì „ ë³´ê³ ì„œ]

ì„¤ë¹„: {state['equipment_id']}
ì ê²€ ì‹œê°: {state['timestamp']}
ìƒíƒœ: ì •ìƒ

ì„¼ì„œ ë°ì´í„°:
{self._format_sensor_data(state['sensor_data'])}

Health Score: {state.get('health_score', 1.0):.1%}
ë‹¤ìŒ ì ê²€: ì •ê¸° PM ìŠ¤ì¼€ì¤„ëŒ€ë¡œ ì§„í–‰
"""
    
    def _format_sensor_data(self, sensor_data: Dict) -> str:
        """ì„¼ì„œ ë°ì´í„° í¬ë§·íŒ…"""
        return "\n".join([f"- {k}: {v}" for k, v in sensor_data.items()])
    
    def _format_root_causes(self, root_causes: List[Dict]) -> str:
        """ì›ì¸ ë¶„ì„ í¬ë§·íŒ…"""
        if not root_causes:
            return "ì›ì¸ ë¶„ì„ ì—†ìŒ"
        
        lines = []
        for cause in root_causes:
            lines.append(
                f"{cause['rank']}ìˆœìœ„: {cause['cause']} "
                f"(í™•ë¥ : {cause['probability']})"
            )
        return "\n".join(lines)
    
    def _format_pm_recommendations(self, pm_recommendations: List[Dict]) -> str:
        """PM ì¶”ì²œì‚¬í•­ í¬ë§·íŒ…"""
        if not pm_recommendations:
            return "ì¶”ì²œì‚¬í•­ ì—†ìŒ"
        
        lines = []
        for rec in pm_recommendations:
            lines.append(
                f"- [{rec['priority']}] {rec['action']}"
            )
        return "\n".join(lines)


# ============================================================================
# 7. Orchestrator (ì›Œí¬í”Œë¡œìš° ê´€ë¦¬)
# ============================================================================

class ManufacturingAISystem:
    """ì „ì²´ Multi-Agent ì‹œìŠ¤í…œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°"""
    
    def __init__(self,
                 lora_model_path: str = "./manufacturing_lora_output",
                 knowledge_base_path: str = "./knowledge_base"):
        
        print("=" * 80)
        print("ğŸ­ AI ììœ¨ ìš´ì˜ ê³µì • ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        print("=" * 80)
        
        # LoRA ì—”ì§„ ì´ˆê¸°í™”
        self.lora_engine = LoRAInferenceEngine(
            lora_adapter_path=lora_model_path
        )
        
        # Agents ì´ˆê¸°í™”
        self.detection_agent = DetectionAgent()
        self.retrieval_agent = RetrievalAgent(knowledge_base_path)
        self.action_agent = ActionAgent(self.lora_engine)
        self.pm_agent = PMRecommendationAgent()
        self.report_agent = ReportAgent(self.lora_engine)
        
        # LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±
        self.workflow = self._build_workflow()
        
        print("\nâœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
        print("=" * 80)
    
    def _build_workflow(self) -> StateGraph:
        """LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±"""
        
        workflow = StateGraph(AgentState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("detect", self.detection_agent.run)
        workflow.add_node("retrieve", self.retrieval_agent.run)
        workflow.add_node("action", self.action_agent.run)
        workflow.add_node("pm", self.pm_agent.run)
        workflow.add_node("report", self.report_agent.run)
        
        # ì—£ì§€ ì •ì˜ (ìˆœì°¨ ì‹¤í–‰)
        workflow.set_entry_point("detect")
        workflow.add_edge("detect", "retrieve")
        workflow.add_edge("retrieve", "action")
        workflow.add_edge("action", "pm")
        workflow.add_edge("pm", "report")
        workflow.add_edge("report", END)
        
        return workflow.compile()
    
    def process_anomaly_event(self,
                              equipment_id: str,
                              sensor_data: Dict[str, float]) -> Dict:
        """ì´ìƒ ì´ë²¤íŠ¸ ì²˜ë¦¬ (ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰)"""
        
        print(f"\n{'='*80}")
        print(f"ğŸš€ ì´ìƒ ì´ë²¤íŠ¸ ì²˜ë¦¬ ì‹œì‘")
        print(f"{'='*80}")
        print(f"ì„¤ë¹„: {equipment_id}")
        print(f"ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ì„¼ì„œ: {sensor_data}")
        
        # ì´ˆê¸° ìƒíƒœ êµ¬ì„±
        initial_state = {
            "equipment_id": equipment_id,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "sensor_data": sensor_data,
            "messages": [],
            "workflow_start_time": datetime.now().isoformat(),
            "workflow_status": "running"
        }
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        start_time = datetime.now()
        
        try:
            result = self.workflow.invoke(initial_state)
            
            # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
            elapsed = (datetime.now() - start_time).total_seconds()
            result['workflow_status'] = 'completed'
            result['elapsed_time'] = elapsed
            
            print(f"\n{'='*80}")
            print(f"âœ… ì›Œí¬í”Œë¡œìš° ì™„ë£Œ (ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ)")
            print(f"{'='*80}")
            
            # ê²°ê³¼ ìš”ì•½
            self._print_summary(result)
            
            return result
            
        except Exception as e:
            print(f"\nâŒ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            raise
    
    def _print_summary(self, result: Dict):
        """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\nğŸ“Š ì‹¤í–‰ ê²°ê³¼ ìš”ì•½:")
        print(f"   - ì´ìƒ ì—¬ë¶€: {'ğŸš¨ ì´ìƒ ê°ì§€' if result.get('is_anomaly') else 'âœ… ì •ìƒ'}")
        
        if result.get('is_anomaly'):
            print(f"   - ì´ìƒ ìœ í˜•: {result.get('anomaly_type')}")
            print(f"   - ì‹ ë¢°ë„: {result.get('anomaly_score', 0):.1%}")
            print(f"   - ê²€ìƒ‰ëœ ì‚¬ë¡€: {len(result.get('similar_cases', []))}ê°œ")
            print(f"   - ì›ì¸ í›„ë³´: {len(result.get('root_causes', []))}ê°œ")
            print(f"   - ì²´í¬ë¦¬ìŠ¤íŠ¸: {len(result.get('checklist', []))}ê°œ")
            print(f"   - Health Score: {result.get('health_score', 0):.1%}")
            print(f"   - ê³ ì¥ ìœ„í—˜ë„: {result.get('failure_risk', 0):.1%}")
            print(f"   - PM ì¶”ì²œ: {len(result.get('pm_recommendations', []))}ê°œ")
        
        print(f"\nğŸ”„ ì‹¤í–‰ ë¡œê·¸:")
        for msg in result.get('messages', []):
            print(f"   {msg}")


# ============================================================================
# 8. ë©”ì¸ ì‹¤í–‰ ì˜ˆì œ
# ============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    system = ManufacturingAISystem(
        lora_model_path="./manufacturing_lora_output",
        knowledge_base_path="./knowledge_base"
    )
    
    # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ 1: ì˜¨ë„ ì´ìƒ
    print("\n" + "=" * 80)
    print("í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ 1: ì˜¨ë„ ì´ìƒ")
    print("=" * 80)
    
    result1 = system.process_anomaly_event(
        equipment_id="ì‚¬ì¶œê¸°-2í˜¸ê¸°",
        sensor_data={
            "temperature": 235.5,
            "pressure": 120.0,
            "vibration": 1.2,
            "cycle_time": 52
        }
    )
    
    # ê²°ê³¼ ì €ì¥
    with open("result_temperature_anomaly.json", "w", encoding="utf-8") as f:
        json.dump(result1, f, ensure_ascii=False, indent=2, default=str)
    
    print("\nâœ… ê²°ê³¼ ì €ì¥: result_temperature_anomaly.json")
    
    # 8D Report ì¶œë ¥
    print("\n" + "=" * 80)
    print("ğŸ“„ ìƒì„±ëœ 8D Report")
    print("=" * 80)
    print(result1.get('report_8d', 'N/A'))
    
    
    # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ 2: ì •ìƒ ìš´ì „
    print("\n\n" + "=" * 80)
    print("í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ 2: ì •ìƒ ìš´ì „")
    print("=" * 80)
    
    result2 = system.process_anomaly_event(
        equipment_id="CNC-1í˜¸ê¸°",
        sensor_data={
            "temperature": 200.0,
            "pressure": 120.0,
            "vibration": 1.0,
            "cycle_time": 50
        }
    )
    
    print("\nâœ… ì •ìƒ ìš´ì „ í™•ì¸")


if __name__ == "__main__":
    # í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs("./knowledge_base", exist_ok=True)
    os.makedirs("./manufacturing_lora_output", exist_ok=True)
    
    print("""
    âš ï¸  ì£¼ì˜ì‚¬í•­:
    1. LoRA ëª¨ë¸ í•™ìŠµì´ ë¨¼ì € ì™„ë£Œë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
       â†’ python train_lora.py
    
    2. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜:
       â†’ pip install langchain langgraph faiss-cpu sentence-transformers
    
    3. GPU ë©”ëª¨ë¦¬ ì¶©ë¶„í•œì§€ í™•ì¸ (ìµœì†Œ 20GB ê¶Œì¥)
    """)
    
    # ì‹¤í–‰
    main()